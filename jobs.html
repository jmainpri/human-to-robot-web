<!DOCTYPE HTML>
<html>
	<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>HRM Research Group</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Humans to Robots Research Group" />
    <meta name="keywords" content="Stuttgart University Robotics Humans to Robots Research Group Max Planck for Intelligent Systems" />
    <meta name="author" content="Jim Mainprice" />

	<!-- 
	//////////////////////////////////////////////////////

	FREE HTML5 TEMPLATE 
	DESIGNED & DEVELOPED by FreeHTML5.co
		
	Website: 		http://freehtml5.co/
	Email: 			info@freehtml5.co
	Twitter: 		http://twitter.com/fh5co
	Facebook: 		https://www.facebook.com/fh5co

	//////////////////////////////////////////////////////
	 -->

  	<!-- Facebook and Twitter integration -->
	<meta property="og:title" content=""/>
	<meta property="og:image" content=""/>
	<meta property="og:url" content=""/>
	<meta property="og:site_name" content=""/>
	<meta property="og:description" content=""/>
	<meta name="twitter:title" content="" />
	<meta name="twitter:image" content="" />
	<meta name="twitter:url" content="" />
	<meta name="twitter:card" content="" />

	<link href="https://fonts.googleapis.com/css?family=Work+Sans:300,400,500,700,800" rel="stylesheet">
	
	<!-- Animate.css -->
	<link rel="stylesheet" href="css/animate.css">
	<!-- Icomoon Icon Fonts-->
	<link rel="stylesheet" href="css/icomoon.css">
	<!-- Bootstrap  -->
	<link rel="stylesheet" href="css/bootstrap.css">
    <!-- Academic icons -->
    <link rel="stylesheet" href="css/academicons.css"/>
	
	<!-- Owl Carousel  -->
	<link rel="stylesheet" href="css/owl.carousel.min.css">
	<link rel="stylesheet" href="css/owl.theme.default.min.css">

	<!-- Theme style  -->
	<link rel="stylesheet" href="css/style.css">

	<!-- Modernizr JS -->
	<script src="js/modernizr-2.6.2.min.js"></script>
	<!-- FOR IE9 below -->
	<!--[if lt IE 9]>
	<script src="js/respond.min.js"></script>
	<![endif]-->

	</head>
	<body>
		
	<div class="fh5co-loader"></div>
	
	<div id="page">
	<nav class="fh5co-nav" role="navigation">
		<div class="top">
			<div class="container">
				<div class="row">
					<div class="col-xs-12 text-right">
						<!-- <p class="num">Call: +01 123 456 7890</p> -->
						<ul class="fh5co-social">

                            <li><a target="_blank" href="https://www.youtube.com/channel/UCVe0W0-tDpHaTuxLB8DmV2g">
                            <i class="icon-youtube"></i></a></li>
                            
                            <li><a target="_blank" href="https://scholar.google.com/citations?user=ToU9KBUAAAAJ&hl=en">
                            <i class="ai ai-google-scholar-square ai-3x"></i></a></li>

                            <li><a target="_blank" href="https://www.researchgate.net/profile/Jim_Mainprice">
                            <i class="ai ai-researchgate ai-3x"></i></a></li>
                            
                            <li><a target="_blank" href="https://www.linkedin.com/in/jim-mainprice-4b29481b/">
                            <i class="icon-linkedin"></i></a></li>

                            <li><a target="_blank" href="https://twitter.com/JimDesMatelles">
                            <i class="icon-twitter"></i></a></li>
						</ul>
					</div>
				</div>
			</div>
		</div>
		<div class="top-menu">
			<div class="container">
				<div class="row">
					<div class="col-xs-2">
						 <!-- <div id="fh5co-logo"><a href="index.html">Run<span>.</span></a></div> -->
					    </div>
					<div class="col-xs-10 text-right menu-1">
						<ul>
                            <li><a href="index.html">Home</a></li>
                            <li><a href="research.html">Research</a></li>
                            <li class="active"><a href="about.html">People</a></li>
                            <li><a href="work.html">Publications</a></li>
                            <li><a href="contact.html">Contact</a></li>
						</ul>
					</div>
				</div>
				
			</div>
		</div>
	</nav>

	<header id="fh5co-header" class="fh5co-cover fh5co-cover-sm" role="banner" 
    style="background-image:url(images/background.png);" data-stellar-background-ratio="0.5">
		<div class="overlay"></div>
		<div class="container">
			<div class="row">
				<div class="col-md-8 col-md-offset-2 text-center">
					<div class="display-t">
						<div class="display-tc animate-box" data-animate-effect="fadeIn">
							<h1>Jobs</h1>
							<!-- <h2>Free HTML5 Bootstrap Template Made by <a href="http://freehtml5.co/" target="_blank">FreeHTML5.co</a></h2> -->
						</div>
					</div>
				</div>
			</div>
		</div>
	</header>
	

	<div id="fh5co-started">
		<div class="container">
			<div class="row animate-box">
				<div class="col-md-8 col-md-offset-2 text-justified fh5co-heading" id="post-doc-offer">
					<h2>Post-doctorate Offer</h2>
					<p>The Max Planck Institute for Intelligent Systems in collaboration with University of Stuttgart 
                    is looking for a Postdoctoral fellow.
                    </p>
                    <p>
                    <b>
                        Title: Postdoctoral position in autonomous manipulation
                    </b>
                    </p>
                    <p>
                    The research project, which will be developed and refined with the candidate, will be to 
                    investigate inverse optimal control and motion optimization algorithms to predict and study 
                    human motor behavior, and its application to human-robot collaboration or human-robot space sharing.
                    </p>
                    <p>
                    Topics:
                    <font color="#888">
                    <li>Machine Learning</li>
                    <li>Inverse Optimal Control</li>
                    <li>Motion Generation</li>
                    <li>Robotic Manipulation</li>
                    <li>Human Movement Understanding</li>
                    <li>Learning from Demonstration</li>
                    <li>Reinforcement Learning or Adaptive Control</li>
                    <li>Human-Robot Interaction and Cooperation</li>
                    </font>
                    </p>
                    <p>
                    The candidate must hold a Ph.D. in robotics, engineering or computer science. 
                    Strong programming and communication skills with an excellent academic track 
                    record are required. Apart from machine learning and motion generation, 
                    experience with motion capture of human motion and bio-mechanics would be highly 
                    appreciated, as well as experience with python, C++ and ROS.
                    </p>
                    <p>
                    The position will take place within a collaboration between the Max Planck Institute (MPI) 
                    for Intelligent Systems (Autonomous Motion Department) in Tübingen, Germany and the 
                    University of Stuttgart, Germany. The MPI and the University of Stuttgart are elements 
                    of the Baden-Württemberg’s "Cyber Valley" initiative, which aims to foster academic 
                    and industrial research in the area of artificial intelligence. The labs are equipped 
                    with dual arm manipulators (Kuka, Baxter, PR2, Sarcos Humanoid, Pepper) 
                    and motion capture capacities (Vicon and OptiTrack).
                    </p>

                    <p>The minimal length of the contract is one year, 
                    but this will be determined with the applicant.</p>

                    <h3><font color="#FFF">How to Apply</font></h3>
                    <p>
                    To send by e-mail to Dr. Jim Mainprice.
                    <ol>
                    <font color="#888">
                    <li>Research project (1 page max.), describe work that you intend to 
                    carry out over the next two years.</li>
                    <li>CV (please include: your nationality for visa requirements, date of birth, 
                    your English level, complete list of scientific publications, 
                    with impact factor of journals, underline your name in the list of authors). 
                    Summarize your past experience in half a page. Mention teaching experience and 
                    other participation in research or outreach projects. 
                    Please include your 3 major publications.</li>
                    <li>List of at least 3 referees (support-letter writers).
                    These referees will be contacted only in case your application is considered.</li>
                    </ol>
                    </font>
                    </p>
                    <p>The position is open immediately until filled. The selected applicants will be 
                    invited for a seminar before hiring.</p>
                    <div class="row animate-box">
                    <div class="col-md-8 col-md-offset-2 text-center">
                      <p><a href="mailto:hrm.jobs@ipvs.uni-stuttgart.de" 
                      class="btn btn-default btn-lg">Apply</a></p>
                    </div>
                </div>
            </div>
            
            </div>
                <div class="col-md-8 col-md-offset-2 text-justified fh5co-heading"
                 id="phd-offers">
                    <h2>Ph.D. Student Offers</h2>
                    <p>
                    Title: Funded Ph.D. student positions in autonomous motion
                    </p>
                    <p>
                    We are looking for students interested to pursue research in imitation and reinforcement learning. The candidates must hold a Master's degree in one of the following fields: computer science, robotics, engineering or physics. Excellent academic track record in the Masters is required. A good scientific culture, strong skills in mathematics, and a good level of English are also required.
                    </p>
                    <p>
                    Previous participation in scientific work with or without publications would be highly appreciated, as well as experience with programming languages (C++ and Python) and deep learning frameworks (e.g., TensorFlow, Torch, Caffe).
                    </p>
                    <p>
                    The positions are within the Humans to Robots Movement (HRM) Research Group of the Machine Learning & Robotics Laboratory. Located at the University of Stuttgart, the laboratory is equipped with PR2 and Baxter robots and a motion capture system.
                    </p>

                    <p>The positions are funded by the university for 3 years.</p>

                    <h3><font color="#FFF">How to Apply</font></h3>
                    <p>
                    To send by e-mail to Dr. Jim Mainprice.
                    <ol>
                    <font color="#888">
                    <li>Motivation letter (1 page max.).</li>
                    <li>CV (please include: your nationality for visa requirements, date of birth, 
                    your English level, list of scientific publications if any).</li>
                    <li>List of at least 2 referees (support-letter writers).
                        These referees will be contacted only in case your application is considered.</li>
                    </ol>
                    </font>
                </div>
                <div class="row animate-box">
                    <div class="col-md-8 col-md-offset-2 text-center">
                        <p><a href="mailto:hrm.jobs@ipvs.uni-stuttgart.de" 
                          class="btn btn-default btn-lg">Apply</a></p>
                    </div>
                </div>
			</div>
		</div>
	</div>

    <div id="fh5co-started">
        <div class="container">
            <div class="row animate-box">
                <div class="col-md-8 col-md-offset-2 text-justified fh5co-heading" id="master-thesis-offer-1">
                    <h2>
                        Master Thesis Offer (1)
                    </h2>
                    <p><b>
                    Title: Neural network user intent prediction for robot teleoperation
                    </b></p>
                    <p>
                    The goal of this thesis is to develop a machine learning framework for user intent prediction during robot teleoperation using eye and a hand gesture tracking hardware (Pupil & LeapMotion). Robot teleoperation refers to the human control of a robot remotely which is especially relevant in unstructured environments. A traditional approach to robot teleoperation is to provide commands mapped to robot actions directly. However this can result in tedious teleoperation especially when the feedback provided by the robot is noisy. This can be alleviated by operating semi-autonomously towards mid-level goals, and user intent prediction can increase performance by allowing the robot to anticipate and disambiguate the user commands. In this context we are developing a robot teleoperation approach based on low dimensional input (i.e., eye movements and hand gestures), to carry out delicate manipulation task with a dual arm manipulator such as the Baxter robot present in our lab.

                    <br><br>
                    The student will take part in this project by 1) performing data collection and 2) developing a machine learning algorithm for intent prediction based on a recurrent neural network implemented in Keras or Pytorch. Knowledge of Python and machine learning is required.

                    <br><br>
                        This master thesis will be based between the Machine Learning and Robotics Lab of the University of Stuttgart and supervised by Dr. Jim Mainprice.
                    <br><br>
                    Links:
                        <font color="#888">

                        <li><a href="https://pytorch.org">Pytroch</a>
                        </li>
                        
                        <li><a href="https://www.youtube.com/results?search_query=leap+motion">Leap Motion Video</a>
                        </li>

                        <li><a href="https://www.youtube.com/watch?v=OdE_Kj1aPkY">RTP vs. RMG Video</a>
                        </li>

                    </p>

                        <div class="row animate-box">
                            <div class="col-md-8 col-md-offset-2 text-center">
                              <p><a href="mailto:hrm.jobs@ipvs.uni-stuttgart.de" 
                              class="btn btn-default btn-lg">Apply</a></p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

    <div id="fh5co-started">
        <div class="container">
            <div class="row animate-box">
                <div class="col-md-8 col-md-offset-2 text-justified fh5co-heading" id="master-thesis-offer-2">
                    <h2>Master Thesis Offer (2)</h2>
                    <p><b>
                    Title:  Learning robotic reactive behavior from human demonstration via dynamic behavior trees
                    </b></p>
                    <p>
                        Robot Learning from Demonstration (LfD) of complex tasks is usually performed in the context of Hierarchical Task Network (HTN) or Markov Decision Processes. While these approaches can be successful, it only allows the robot to reason in terms of sequential planning. The selected candidate will investigate a new method for LfD problems, which models the human demonstrations using dynamic behavior trees. This new paradigm would allow a robot to reason not only in terms of task accomplishment, but also in terms of sensory motor couplings to implement behaviors at runtime. The resulting reactivity would increase the robustness and liveliness of the robot.
                        <br><br>
                        The student will develop a framework extending the Playful scripting language for learning behavior trees. After an initial phase using synthetic demonstrations the student will develop an approach for learning demonstrations using data recorded using the OptiTrack motion capture and Motive body tracker present in our Lab in Stuttgart. The learned behavior will be tested on the baxter robot, which already integrates the Playful framework. The selected candidate must have excellent working knowledge of machine learning and python, as well as a motivation to test his work on a real working robot. A good knowledge of ROS is a plus.
                        <br><br>
                        This master thesis will be based between the Machine Learning and Robotics Lab of the University of Stuttgart and the Max Planck Institute for Intelligent Systems in Stuttgart and jointly supervised by Dr. Jim Mainprice and Dr. Vincent Berenz.
                        </p>

                        Links:
                        <font color="#888">

                        <li><a href="https://ipvs.informatik.uni-stuttgart.de/mlr/">Machine Learning and Robotics Lab</a> 
                        </li>

                        <li><a href="https://ipvs.informatik.uni-stuttgart.de/mlr/HRM/">Humans to Robots Motion (HRM) group</a>
                        </li>

                        <li><a href="https://www.is.mpg.de/de/publications/playful">Playful</a>
                        </li>

                        <li><a href="https://sites.google.com/site/jimmainprice"> Dr. Jim Mainprice (HRM)</a>
                        </li>

                        <li><a href="https://www.is.mpg.de/de/employees/vberenz"> Dr. Vincent Berenz (Max Planck Institute for Intelligent Systems)</a>
                        </li>

                        <br>
                        <p>
                        <div class="row animate-box">
                            <div class="col-md-8 col-md-offset-2 text-center">
                              <p><a href="mailto:hrm.jobs@ipvs.uni-stuttgart.de" 
                              class="btn btn-default btn-lg">Apply</a></p>
                            </div>
                        </div>

                    </div>
                </div>
            </div>
        </div>


   <div id="fh5co-started">
        <div class="container">
            <div class="row animate-box">
                <div class="col-md-8 col-md-offset-2 text-justified fh5co-heading" id="master-thesis-offer-3">
                    <h2>Master Thesis Offer (3)</h2>
                    <p><b>
                    Title:  Hierarchical Inverse Reinforcement Learning from Motion Capture Data
                    </b></p>
                    <p>
                        Inverse reinforcement learning is the process of deriving a reward function from observed behavior. Recent work mainly focuses on solving one task and therefore only one global reward function is learned. However, human motion generally consists of multiple low-level tasks which have to be performed in a defined order or in parallel in order to achieve a high-level task. For example, making pizza dough consists of several low-level tasks, such as, measuring water, adding yeast, measuring flour, etc, In this project, the student will investigate the problem of hierarchical inverse reinforcement learning, which aims to learn multiple reward functions for low-level tasks, together with a latent state space representation to encode the higher-level task objective based on human demonstrations of full body motion performing the high-level task.
                        <br><br>
                        The student will develop an algorithmic framework for hierarchical inverse reinforcement learning. Example motion data will be recorded using the OptiTrack motion capture system in our Lab. The learned behavior will be tested in simulation using a simplified kinematic model of a human. The student should have experience in machine learning and reinforcement learning.
                        <br><br>
                        This master thesis will be based at the Machine Learning and Robotics Lab of the University of Stuttgart and jointly supervised by Dr. Jim Mainprice and Ms. Philipp Kratzer.
                        </p>

                        Links:
                        <font color="#888">

                        <li><a href="https://ipvs.informatik.uni-stuttgart.de/mlr/">Machine Learning and Robotics Lab</a> 
                        </li>

                        <li><a href="https://ipvs.informatik.uni-stuttgart.de/mlr/HRM/">Humans to Robots Motion (HRM) group</a>
                        </li>

                        <li><a href="https://sites.google.com/site/jimmainprice"> Dr. Jim Mainprice (HRM)</a>
                        </li>


                        <br>
                        <p>
                        <div class="row animate-box">
                            <div class="col-md-8 col-md-offset-2 text-center">
                              <p><a href="mailto:hrm.jobs@ipvs.uni-stuttgart.de" 
                              class="btn btn-default btn-lg">Apply</a></p>
                            </div>
                        </div>

                    </div>
                </div>
            </div>
        </div>


   <div id="fh5co-started">
        <div class="container">
            <div class="row animate-box">
                <div class="col-md-8 col-md-offset-2 text-justified fh5co-heading" id="master-thesis-offer-4">
                    <h2>Master Thesis Offer (4)</h2>
                    <p><b>
                    Title: Neural network user intent prediction for robot mobile teleoperation
                    </b></p>
                    <p>

                        The goal of this thesis is to develop a machine learning framework for user intent prediction during robot teleoperation using eye tracking and hand gesture tracking hardware (Pupil & LeapMotion). Robot teleoperation refers to the human control of a robot remotely which is especially relevant in unstructured environments. A traditional approach to robot teleoperation is to provide commands mapped to robot actions directly. However this can result in tedious teleoperation especially when the feedback provided by the robot is noisy. This can be alleviated by operating semi-autonomously towards mid-level goals, and user intent prediction can increase performance by allowing the robot to anticipate and disambiguate the user commands. In this context we are developing a robot teleoperation user interface that utilizes human gaze and hand gestures to infer the user's goal and carry out mobile manipulation tasks, such as driving a robot to a certain location when the user intends to perform tasks at that certain region in the environment. The student will be working with a simulated environment of the PR2 Robot using ROS Gazebo. The student will take part in this project by 1) setting up a simulated environment using Gazebo and 2) developing a machine learning algorithm for intent prediction using machine learning algorithms such as recurrent neural networks implemented in Keras, or Tensorflow. Knowledge of Python and machine learning is required, and knowledge of ROS(Robot Operating System) is preferred.
                        <br><br>
                        This master thesis will be based at the Machine Learning and Robotics Lab of the University of Stuttgart and jointly supervised by Dr. Jim Mainprice and Ms. Yoojin Oh.
                        </p>

                        Links:
                        <font color="#888">

                        <li><a href="https://ipvs.informatik.uni-stuttgart.de/mlr/">Machine Learning and Robotics Lab</a> 
                        </li>

                        <li><a href="https://ipvs.informatik.uni-stuttgart.de/mlr/HRM/">Humans to Robots Motion (HRM) group</a>
                        </li>

                        <li><a href="https://sites.google.com/site/jimmainprice"> Dr. Jim Mainprice (HRM)</a>
                        </li>


                        <br>
                        <p>
                        <div class="row animate-box">
                            <div class="col-md-8 col-md-offset-2 text-center">
                              <p><a href="mailto:hrm.jobs@ipvs.uni-stuttgart.de" 
                              class="btn btn-default btn-lg">Apply</a></p>
                            </div>
                        </div>

                    </div>
                </div>
            </div>
        </div>


   <div id="fh5co-started">
        <div class="container">
            <div class="row animate-box">
                <div class="col-md-8 col-md-offset-2 text-justified fh5co-heading" id="master-thesis-offer-5">
                    <h2>Master Thesis Offer (5)</h2>
                    <p><b>
                    Title: Learning Reactive Programs for Interactive Robots
                    </b></p>
                    <p>
                        Social robots or collaborative robots that have to interact with people in a reactive way are difficult to program. This difficulty stems from the different skills required by the programmer: to provide an engaging user experience the behavior must include a sense of aesthetics while robustly operating in a continuously changing environment. To facilitate non expert users to program such behaviors, we research a new Learning from Demonstration (LfD)  technique  that  maps  motion  capture  of  humans  to  a script that can be directly applied on its dedicated robot. Our method leverage our experience in applying reactive programming to robotic orchestration [1].
                        <br>
                        <br>
                        In [2], we successfully transfered from a human demonstrator to a robot the skills to perform an interactive task, in which the goal is to attract the attention of another human passing by. The algorithm infer from a trained Hidden Markov Model the set of robot primitives that should be activated to reconstruct the demonstrated behavior, and generate on the fly the related reactive program. Expected advantages of the approach are behavioral reactivity and generalization.
                        <br><br>
                        The algorithm has been applied in a world model consisting of only a single linear feature. For more complex scenarios, it must be extended using supervised learning techniques.
                        </p>
                        <li>See video: <a href="https://www.youtube.com/watch?v=wGoBwkFZm08&feature=youtu.be">YouTube [2]</a>
                        </li>
                        <br><br>
                        <b>Project Outline</b>
                        <br>
                        An outline of the main parts and subtasks of this project is given below. This list is not necessarily in the order of planned execution, and it is subject to adjustments during the project whenever required. The project has a strong research component, so its outcome cannot accurately be foreseen at the project start, and the project scope may be adjusted accordingly.
                        <br><br>
                        <i>Introduction and Setup (1.5 months)</i>
                        <br><br>
                        <ul>
                        <li>Familiarize with reactive programming applied to robotics, and existing program</li>
                        <li>Some literature study, mostly on LfD techniques
                        Replicating (using existing code) experiments done in [2]</li>
                        </ul>
                        <br>
                        <i>Machine learning algorithm conception (1.5 months)</i>
                        <br><br>
                        <ul>
                        <li>Casting the research objectives into a supervised learning algorithm</li>
                        </ul>
                        <br>
                        <i>Data collection and robot experiment (3 months)</i>
                        <br><br>
                        <ul>
                        <li>Conceiving a proof of concept of experiment suitable for validating the proposed algorithm</li>
                        <li>Experiment on one of the available robotic platform (with active support from supervisors)</li>
                        </ul>
                        <br><br>
                        <b>Candidate</b>
                        <br>
                        The candidate should have knowledge in machine learning and python programming. Experience with robotics (e.g. ROS) would be a plus. Candidates showing understanding and interest in the research described in [2] will have the highest chance being selected. 
                        <br><br>
                        <li><a href="https://www.researchgate.net/profile/Stefan_Schaal/publication/325077049_Playful_Reactive_Programming_for_Orchestrating_Robotic_Behavior/links/5b8c4e394585151fd1446ff7/Playful-Reactive-Programming-for-Orchestrating-Robotic-Behavior.pdf?_sg%5B0%5D=3CtxCsXjsE9lUhJUFDT6KtSLrVCM7wJlzj0aYuYtzK7-zimBr60Aqke06pwRfGMnOWa9SE0hWlkGDvs0apr9Wg.f87hwuPfkvWyJO_pZSu5Ano9rLXFz508Wtpu3T1lpPFWI7zWeRfePP-lm05gU8dAcYNTLM3r4PKCd6924KrkvQ&_sg%5B1%5D=t-k5Lm_FHijKnMZxeC7Df3MN-a-bwNAOEZs1iX9vMM7q4ufEVSWy3coAWhF742TYzq-_N-k9rVHzMpQDzdpgbW2U2fqniIdOYISXHEOn6j5q.f87hwuPfkvWyJO_pZSu5Ano9rLXFz508Wtpu3T1lpPFWI7zWeRfePP-lm05gU8dAcYNTLM3r4PKCd6924KrkvQ&_iepl=">[1]
                        Berenz, V., Schaal, S, "Playful: Reactive Programming for Orchestrating Robotic Behavior", IEEE Robotics Automation Magazine, 25(3):49-60, September 2018</a>
                        </li>
                        <li><a href="https://arxiv.org/pdf/1903.01352">[2] Berenz, V., Bjelic, A., Mainprice, J, "Automated Generation of Reactive Programs from Human Demonstration for Orchestration of Robot Behaviors", ArXiv, 2019</a>
                        </li>
                        <br><br>
                        This master thesis will be based at the Machine Learning and Robotics Lab of the University of Stuttgart and jointly supervised by Dr. Vincent Berenz and Dr. Jim Mainprice.
                        </p>

                        Links:
                        <font color="#888">

                        <li><a href="https://playful.is.tuebingen.mpg.de/">Playful</a>
                        </li>

                        <li><a href="https://ipvs.informatik.uni-stuttgart.de/mlr/">Machine Learning and Robotics Lab</a> 
                        </li>

                        <li><a href="https://sites.google.com/site/jimmainprice"> Dr. Jim Mainprice (HRM)</a>
                        </li>

                        <li><a href="https://www.is.mpg.de/de/employees/vberenz"> Dr. Vincent Berenz (MPI)</a>
                        </li>


                        <br>
                        <p>
                        <div class="row animate-box">
                            <div class="col-md-8 col-md-offset-2 text-center">
                              <p><a href="mailto:hrm.jobs@ipvs.uni-stuttgart.de" 
                              class="btn btn-default btn-lg">Apply</a></p>
                            </div>
                        </div>

                    </div>
                </div>
            </div>
        </div>


   <div id="fh5co-started">
        <div class="container">
            <div class="row animate-box">
                <div class="col-md-8 col-md-offset-2 text-justified fh5co-heading" id="tamp-thesis-offer">
                    <h2>Thesis Offer</h2>
                    <p><b>
                    Title: Task and Motion Planning for Collaborative Robots
                    </b></p>
                    <p>
                    In this thesis, you will tackle the problem of human-robot coordination in sequences of manipulation tasks. The approach integrates hierarchical human motion prediction with Task and Motion Planning (TAMP).
                    <br><br>
                    You will first devise a motion prediction system for long-term tasks using hierarchical inverse optimal control. You will assess the efficacy of the approach by training the prediction algorithms and test the framework on the publicly available MoGaze dataset [1]. 
                    <br><br>
                    In a second step, you will integrate a dynamic version of the TAMP algorithm Logic-Geometric Programming (LGP) [2] on the Pepper robot available at our lab. Our version of Dynamic LGP [3], replans periodically to handle the mismatch between the human motion prediction and the actual human behavior.
                    <br><br>
                    Inverse optimal control (a.k.a. inverse reinforcement learning) is the process of deriving a reward function from observed behavior. Recent work mainly focuses on solving one task and therefore only one global reward function is learned. However, human motion generally consists of multiple low-level tasks which have to be performed in a defined order or in parallel in order to achieve a high-level task. For example, making pizza dough consists of several low-level tasks, such as, measuring water, adding yeast, measuring flour, etc, In this project, the student will investigate the problem of hierarchical inverse reinforcement learning, which aims to learn multiple reward functions for low-level tasks, together with a latent state space representation to encode the higher-level task objective based on human demonstrations of full body motion performing the high-level task.
                    <br><br>
                    This master thesis will be based at the Machine Learning and Robotics Lab of the University of Stuttgart and jointly supervised by Dr. Jim Mainprice and Ms. Philipp Kratzer.
                    <br><br>
                    [1] Kratzer, P., Bihlmaier, S., Midlagajni, N. B., Prakash, R., Toussaint, M., & Mainprice, J. (2020). Mogaze: A dataset of full-body motions that includes workspace geometry and eye-gaze. IEEE Robotics and Automation Letters, 6(2), 367-373.
                    <br><br>
                    [2] Toussaint, M. (2015, June). Logic-geometric programming: An optimization-based approach to combined task and motion planning. In Twenty-Fourth International Joint Conference on Artificial Intelligence.
                    <br><br>
                    [3] Le, A. T., Kratzer, P., Hagenmayer, S., Toussaint, M., & Mainprice, J. (2021). Hierarchical Human-Motion Prediction and Logic-Geometric Programming for Minimal Interference Human-Robot Tasks. arXiv preprint arXiv:2104.08137.
                    <br><br>

                        Links:
                        <font color="#888">

                        <li><a href="https://ipvs.informatik.uni-stuttgart.de/mlr/">Machine Learning and Robotics Lab</a> 
                        </li>

                        <li><a href="https://ipvs.informatik.uni-stuttgart.de/mlr/HRM/">Humans to Robots Motion (HRM) group</a>
                        </li>

                        <li><a href="https://sites.google.com/site/jimmainprice"> Dr. Jim Mainprice (HRM)</a>
                        </li>

                        <li><a href="https://arxiv.org/pdf/2104.08137.pdf"> Dynamic LGP paper</a>
                        </li>

                        <li><a href="https://www.softbankrobotics.com/emea/en/pepper">Pepper robot</a>
                        </li>

                        <br>
                        <p>
                        <div class="row animate-box">
                            <div class="col-md-8 col-md-offset-2 text-center">
                              <p><a href="mailto:hrm.jobs@ipvs.uni-stuttgart.de" 
                              class="btn btn-default btn-lg">Apply</a></p>
                            </div>
                        </div>

                    </div>
                </div>
            </div>
        </div>

    <div id="fh5co-started">
        <div class="container">
            <div class="row animate-box">
                <div class="col-md-8 col-md-offset-2 text-justified fh5co-heading" id="master-thesis-offer-2">
                    <h2>Thesis Offer</h2>
                    <p><b>
                    Title:  Learning robotic reactive behavior from human demonstration via dynamic behavior trees
                    </b></p>
                    <p>
                        Robot Learning from Demonstration (LfD) of complex tasks is usually performed in the context of Hierarchical Task Network (HTN) or Markov Decision Processes. While these approaches can be successful, it only allows the robot to reason in terms of sequential planning. The selected candidate will investigate a new method for LfD problems, which models the human demonstrations using dynamic behavior trees. This new paradigm would allow a robot to reason not only in terms of task accomplishment, but also in terms of sensory motor couplings to implement behaviors at runtime. The resulting reactivity would increase the robustness and liveliness of the robot.
                        <br><br>
                        The student will develop a framework extending the Playful scripting language for learning behavior trees. After an initial phase using synthetic demonstrations the student will develop an approach for learning demonstrations using data recorded using the OptiTrack motion capture and Motive body tracker present in our Lab in Stuttgart. The learned behavior will be tested on the baxter robot, which already integrates the Playful framework. The selected candidate must have excellent working knowledge of machine learning and python, as well as a motivation to test his work on a real working robot. A good knowledge of ROS is a plus.
                        <br><br>
                        This master thesis will be based between the Machine Learning and Robotics Lab of the University of Stuttgart and the Max Planck Institute for Intelligent Systems in Stuttgart and jointly supervised by Dr. Jim Mainprice and Dr. Vincent Berenz.
                        </p>

                        Links:
                        <font color="#888">

                        <li><a href="https://ipvs.informatik.uni-stuttgart.de/mlr/">Machine Learning and Robotics Lab</a> 
                        </li>

                        <li><a href="https://ipvs.informatik.uni-stuttgart.de/mlr/HRM/">Humans to Robots Motion (HRM) group</a>
                        </li>

                        <li><a href="https://www.is.mpg.de/de/publications/playful">Playful</a>
                        </li>

                        <li><a href="https://sites.google.com/site/jimmainprice"> Dr. Jim Mainprice (HRM)</a>
                        </li>

                        <li><a href="https://www.is.mpg.de/de/employees/vberenz"> Dr. Vincent Berenz (Max Planck Institute for Intelligent Systems)</a>
                        </li>

                        <br>
                        <p>
                        <div class="row animate-box">
                            <div class="col-md-8 col-md-offset-2 text-center">
                              <p><a href="mailto:hrm.jobs@ipvs.uni-stuttgart.de" 
                              class="btn btn-default btn-lg">Apply</a></p>
                            </div>
                        </div>

                    </div>
                </div>
            </div>
        </div>

	<footer id="fh5co-footer" role="contentinfo">
		<div class="container">
			<div class="row copyright">
				<div class="col-md-12 text-center">
                <p>
                    <ul class="fh5co-social-icons">

                            <p> Social media </p>
                            
                            <li><a target="_blank" href="https://scholar.google.com/citations?user=ToU9KBUAAAAJ&hl=en">
                            <i class="ai ai-google-scholar-square ai-3x"></i></a></li>

                            <li><a target="_blank" href="https://www.researchgate.net/profile/Jim_Mainprice">
                            <i class="ai ai-researchgate ai-3x"></i></a></li>
                            
                            <li><a target="_blank" href="https://www.linkedin.com/in/jim-mainprice-4b29481b/">
                            <i class="icon-linkedin"></i></a></li>
                    </ul>
                </p>
                <p>
                    <small class="block">&copy; 2016 Free HTML5. All Rights Reserved.</small> 
                    <small class="block">Designed by <a href="http://freehtml5.co/" 
                    target="_blank">FreeHTML5.co</a> Demo Images: <a href="http://unsplash.co/" 
                    target="_blank">Unsplash</a></small>
                    </p>
				</div>
			</div>
		</div>
	</footer>

	</div>

	<div class="gototop js-top">
		<a href="#" class="js-gotop"><i class="icon-arrow-up"></i></a>
	</div>
	
	<!-- jQuery -->
	<script src="js/jquery.min.js"></script>
	<!-- jQuery Easing -->
	<script src="js/jquery.easing.1.3.js"></script>
	<!-- Bootstrap -->
	<script src="js/bootstrap.min.js"></script>
	<!-- Waypoints -->
	<script src="js/jquery.waypoints.min.js"></script>
	<!-- Stellar Parallax -->
	<script src="js/jquery.stellar.min.js"></script>
	<!-- Carousel -->
	<script src="js/owl.carousel.min.js"></script>
	<!-- Main -->
	<script src="js/main.js"></script>

	</body>
</html>

